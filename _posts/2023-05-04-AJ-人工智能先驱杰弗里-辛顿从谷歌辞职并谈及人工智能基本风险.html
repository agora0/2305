---
layout: post
title: 人工智能先驱杰弗里·辛顿从谷歌辞职并谈及人工智能基本风险
date: 2023-05-04 17:36:03.000000000 +08:00
link: http://chinese.aljazeera.net/technology/2023/5/4/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%85%88%e9%a9%b1%e6%9d%b0%e5%bc%97%e9%87%8c%e8%be%9b%e9%a1%bf%e4%bb%8e%e8%b0%b7%e6%ad%8c%e8%be%9e%e8%81%8c%e5%b9%b6%e8%b0%88%e5%8f%8a%e4%ba%ba%e5%b7%a5
categories: aj
---

<div aria-live="polite" aria-atomic="true"><p>在为谷歌服务 10 年后，人工智能先驱杰弗里·辛顿于上周一从这家美国巨头辞职，他在接受美国《纽约时报》<a href="https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html?searchResultPosition=1">采访</a>时解释说，他离开是为了畅谈人工智能，以及关于人工智能的五个基本风险。</p>
<h3>当心机器比其制造商更聪明</h3>
<p>杰弗里·辛顿表示，大型科技巨头之间的竞争带来了前所未有的进步，进步的速度超出了科学家的预期，“只有少数人相信这项技术实际上可以变得比人类更聪明，我个人认为，这只会在 30 到 50 年或更长时间内发生，当然，现在我不再这么认为了。”</p>
<figure id="attachment_428076" aria-describedby="caption-attachment-428076" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/1-1683191406.png?w=770&amp;resize=770%2C433" alt data-recalc-dims="1" /><figcaption id="caption-attachment-428076">杰弗里·辛顿：唯一的希望是世界上最重要的科学家携手合作，寻找控制人工智能的解决方案（法国媒体）</figcaption></figure>
<p>直到去年，他才认为这一进步是危险的，但当谷歌和 OpenAI 开发出能够处理非常大量数据的神经系统时，他的观点发生了变化，这可能使这些系统比人脑更高效，因此，也极其危险。</p>
<h3>减少所有领域的就业机会</h3>
<p>从经济学的角度来看，这位人工智能教父担心这项技术会严重扰乱就业市场，他并表示，“人工智能扼杀了艰苦的工作，”并补充说“它可以消除的远不止于此，” 尤其影响翻译和私人助理，即使是最“聪明”的人也不会因为工作机会的减少而受到伤害，即使他们中的一些人认为他们不会受到影响。</p>
<figure id="attachment_428079" aria-describedby="caption-attachment-428079" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/1-1683191451.jpg?w=770&amp;resize=770%2C433" alt data-recalc-dims="1" /><figcaption id="caption-attachment-428079">人工智能教父警告这些系统的巨大危险</figcaption></figure>
<h3>“杀手机器人”的威胁</h3>
<p>这位专家认为，与我们现有的规范人工智能使用的手段相比，技术进步非常迅速，他并评论说，“我认为，在我们了解是否可以控制它之前，我们不应该仓促行事。” 这位专家担心的是，未来的释放将成为“对人类的威胁”。</p>
<p>按照辛顿的说法，未来的人工智能系统将能够在分析大量数据后产生意想不到的行为，而这已经成为可能，因为人工智能系统会生成并指挥自己的代码，这可能会将它们变成“自主武器”和“杀手机器人”，尽管许多专家淡化了这种威胁。</p>
<h3>人工智能掌握在恶意行为者手中</h3>
<p>根据辛顿的说法，威胁还来自危险行为者滥用人工智能，他担心“很难弄清楚如何阻止不良行为者将其用于邪恶目的，” 特别是，辛顿反对在军事领域使用人工智能，他主要担心人类会发展出“机器人士兵”。</p>
<p>上世纪八十年代，杰弗里·辛顿决定离开美国卡内基梅隆大学，因为他在那里的研究得到了五角大楼的资助。</p>
<figure id="attachment_428082" aria-describedby="caption-attachment-428082" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/1-1683191626.png?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-428082">杰弗里·辛顿警告不要滥用人工智能（美联社）</figcaption></figure>
<h3>“问题回答者”</h3>
<p>最后，杰弗里·辛顿警告与人工智能相关的错误信息，并强调，这种科学热潮和随之而来的人工智能的广泛使用将使人们几乎无法区分“真假”，以至于全世界都在谈论一个“问题回答者”，这是一种表达方式，指的是人工智能产生有说服力陈述的能力，这些陈述听起来似是而非。</p>
<p>那么，解决方法是什么？神经网络专家支持包括该领域所有专家在内的国际合作，但他怀疑实现这一目标的能力，他并表示，“这可能是不可能的……没有办法知道公司或国家是否在秘密开展此类项目，而唯一的希望是，世界上最重要的科学家将携手合作，找到控制人工智能的解决方案。”</p>
</div><div>来源<!-- --> : <!-- -->纽约时报</div>
