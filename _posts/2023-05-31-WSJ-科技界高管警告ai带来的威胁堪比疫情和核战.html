---
layout: post
title: 科技界高管警告AI带来的威胁堪比疫情和核战
date: 2023-05-31 11:33:03.000000000 +08:00
link: https://cn.wsj.com/amp/articles/%E7%A7%91%E6%8A%80%E7%95%8C%E9%AB%98%E7%AE%A1%E8%AD%A6%E5%91%8Aai%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%A8%81%E8%83%81%E5%A0%AA%E6%AF%94%E7%96%AB%E6%83%85%E5%92%8C%E6%A0%B8%E6%88%98-4cb7878d
categories: wsj
---

<main id="main" role="main">
<div>


</div>
<div itemprop="articleLead" data-sbId="CN-TEC-20230531111020">
    <div>
      <div class="media-object scope-
          header
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-790651?width=540&amp;size=1.4988290398126465 540w, https://images.wsj.net/im-790651?width=620&amp;size=1.4988290398126465 620w, https://images.wsj.net/im-790651?width=639&amp;size=1.4988290398126465 639w, https://images.wsj.net/im-790651?width=860&amp;size=1.4988290398126465 860w, https://images.wsj.net/im-790651?width=860&amp;size=1.4988290398126465&amp;pixel_ratio=1.5 1290w, https://images.wsj.net/im-790651?width=860&amp;size=1.4988290398126465&amp;pixel_ratio=2 1720w, https://images.wsj.net/im-790651?width=860&amp;size=1.4988290398126465&amp;pixel_ratio=3 2580w"
          src="https://images.wsj.net/im-790651?width=860&amp;height=574"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>本月早些时候，OpenAI首席执行官Sam Altman在参议院一个委员会作证后向媒体发表讲话。</p>
    <p> 图片来源：jim lo scalzo/Shutterstock</p>
  </figcaption>
</figure>

      </div>
    </div>
</div>
<div data-sbId="CN-TEC-20230531111020">

<div>

  <div>
      <p> </p>
              <p><span itemprop="name">
                <a href="https://www.wsj.com/news/author/alyssa-lukpat" itemprop="url" rel="author">Alyssa Lukpat</a>
              </span></p>

  </div>
    <time>
      2023年5月31日11:20 CST 更新
    </time>
</div>

<div subscriptions-actions subscriptions-display="NOT data.noSharing">
  <div>
    <social-share type="system" width="72" height="24"
      data-param-url="https://cn.wsj.com/articles/科技界高管警告ai带来的威胁堪比疫情和核战-4cb7878d">
    </social-share>
  </div>
</div>


<div subscriptions-section="content">
</div>
<div subscriptions-section="content-not-granted">
</div>



<section subscriptions-section="content">
      <p>科技界高管和人工智能(AI)科学家正在对AI敲响警钟，他们在周二的一份联合声明中表示，这项技术带来的灭绝风险堪比疫情和核战。</p>
      <p>超过350人签署了人工智能安全中心(Center for AI Safety)发布的一份声明，该组织表示，致力于降低AI风险。</p>
      <p>该组织表示，与疫情和核战争等其他社会规模的风险一样，减轻AI带来的灭绝风险应该成为全球的优先事项。</p>
      <p>签署者表示，他们希望就AI最严重的风险展开讨论。开发了ChatGPT的公司OpenAI的首席执行官Sam Altman和该公司首席技术官Mira Murati也签署了这份声明。</p>
      <div> <p>其他签署者包括微软(Microsoft, MSFT)首席技术官Kevin Scott，谷歌(Google)AI高管Lila Ibrahim和Marian Rogers，以及前联合国裁军事务高级代表Angela Kane。Skype和Quora的领导者也签署了该声明。</p>
      <p>科技行业对AI表达了兴奋之情，但对该技术可能会失控的担忧也在上升。自OpenAI去年发布ChatGPT以来，批评人士加大了对AI进行监管的呼吁，称该技术对人类构成了无法估量的威胁。</p>
      <p>近几个月来，随着投资者押注他们认为的新计算时代，AI股大幅上涨。周二，开发AI技术的半导体公司英伟达(Nvidia, NVDA)成为<a href="https://cn.wsj.com/articles/CN-TEC-20230530143021" target="_blank" >首家估值达到1万亿美元的芯片制造商</a>，加入全球万亿美元公司名单，该名单上还有苹果公司(Apple, AAPL)、微软、亚马逊公司(Amazon.com, AMZN)和谷歌母公司Alphabet (GOOG)。</p>
      <p>今年3月，AI专家和包括马斯克(Elon Musk)在内的科技公司高管签署了一封信，<a href="https://cn.wsj.com/articles/CN-TEC-20230330072855" target="_blank" >呼吁AI开发人员暂停其在这项技术上的工作</a>。他们表示，暂停至少六个月将使该行业有时间为AI设计制定安全标准，并遏制风险最大的AI技术的潜在危害。</p>
      <p>签署者周二表示，虽然公众一直承认AI的风险，但还有更多的挑战需要讨论。他们还希望越来越多的专家和公众人物形成共识，他们也非常重视先进AI的一些最严重的风险。</p>
      <p>这份线上声明还提供了让AI科学家、教授、高管和领导者可以签名的选择。</p>
      <p>AI本质上是指电脑通过从大量数据中学习实现模仿人类反应的能力。</p>
      <p>科技行业多年来一直在开发AI，但在去年11月OpenAI发布ChatGPT后，这项技术得到了更广泛的应用。这个免费的聊天机器人可以快速回答几乎任何问题，可让用户获取工作和学校相关问题的答案。ChatGPT的答案有时是错误的。支持者表示，这项技术有可能改变各个行业，重塑部分工种。</p>
      <p>ChatGPT的发布在谷歌和微软等科技公司中引发了一场推出类似技术的竞赛。</p>
      <p>领导者和科技行业高管已经警告过AI带来的危险，但周二的签署者表示，他们还没有讨论最紧迫的风险。</p>
      <p>拜登政府最近几个月表示，<a href="https://cn.wsj.com/articles/CN-TEC-20230505073204" target="_blank" >AI对公共安全、隐私和民主构成威胁</a>，但政府监管它的权力有限。比尔‧盖茨(Bill Gates)曾表示，<a href="https://cn.wsj.com/articles/CN-TEC-20230323090445" target="_blank" >他认为AI应该得到适当的监管，</a>但他也表达了对这项技术的兴奋之情。他没有在周二的声明上签字。</p>
      <p>网络安全负责人们表示，AI有明显的益处，但早期生成式AI相关承诺和风险都被夸大了。</p>
      </div>
</section>

</div>
      </main>
